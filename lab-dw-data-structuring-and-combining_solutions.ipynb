{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5f497-2c72-422b-86f7-06ad8842fd6d",
   "metadata": {},
   "source": [
    "# Challenge 1: Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b48ba0-101f-4611-b8bc-b4d8e05ab2f5",
   "metadata": {},
   "source": [
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the following links: \n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2_clean.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3_clean.csv\n",
    "\n",
    "Combine the data from the three dataframes into a single dataframe, named \"customer_data\", using appropriate merging, concatenating, and joining techniques.\n",
    "\n",
    "Verify that the customer_data dataframe contains all the rows and columns from the three original dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f531a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Combine- the data from the three dataframes into a single dataframe, named -\"customer_data\"-, \n",
    "#--using appropriate -merging-, -concatenating-, and -joining techniques-.\n",
    "\n",
    "# -Verify- that the -customer_data dataframe- contains -all the rows and columns- from the three original dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed5869a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CONTROLN STATE GENDER      HV1    IC1    IC4  HVP1    IC5  POBC1  \\\n",
      "0       44060.0    FL      M   AAA896  392.0  520.0   7.0  21975    6.0   \n",
      "1       96093.0    IL      M   537.00  365.0  473.0   0.0  19387    1.0   \n",
      "2       43333.0    FL      F   725.00  301.0  436.0   3.0  18837   11.0   \n",
      "3       21885.0    NC      M  AAA1095  401.0  413.0   7.0  14014    1.0   \n",
      "4      190108.0    FL      F   995.00  252.0  348.0   0.0  17991    5.0   \n",
      "...         ...   ...    ...      ...    ...    ...   ...    ...    ...   \n",
      "25150       NaN   NaN      M      NaN    NaN    NaN   NaN    NaN    NaN   \n",
      "25151       NaN   NaN      F      NaN    NaN    NaN   NaN    NaN    NaN   \n",
      "25152       NaN   NaN      M      NaN    NaN    NaN   NaN    NaN    NaN   \n",
      "25153       NaN   NaN      M      NaN    NaN    NaN   NaN    NaN    NaN   \n",
      "25154       NaN   NaN      M      NaN    NaN    NaN   NaN    NaN    NaN   \n",
      "\n",
      "       POBC2  ...  Customer          ST  Education  Customer Lifetime Value  \\\n",
      "0       16.0  ...       NaN         NaN        NaN                      NaN   \n",
      "1       89.0  ...       NaN         NaN        NaN                      NaN   \n",
      "2       17.0  ...       NaN         NaN        NaN                      NaN   \n",
      "3       74.0  ...       NaN         NaN        NaN                      NaN   \n",
      "4        6.0  ...       NaN         NaN        NaN                      NaN   \n",
      "...      ...  ...       ...         ...        ...                      ...   \n",
      "25150    NaN  ...   LA72316  California   Bachelor              23405.98798   \n",
      "25151    NaN  ...   PK87824  California    College              3096.511217   \n",
      "25152    NaN  ...   TD14365  California   Bachelor              8163.890428   \n",
      "25153    NaN  ...   UP19263  California    College              7524.442436   \n",
      "25154    NaN  ...   Y167826  California    College              2611.836866   \n",
      "\n",
      "        Income Monthly Premium Auto  Number of Open Complaints  \\\n",
      "0          NaN                  NaN                        NaN   \n",
      "1          NaN                  NaN                        NaN   \n",
      "2          NaN                  NaN                        NaN   \n",
      "3          NaN                  NaN                        NaN   \n",
      "4          NaN                  NaN                        NaN   \n",
      "...        ...                  ...                        ...   \n",
      "25150  71941.0                 73.0                          0   \n",
      "25151  21604.0                 79.0                          0   \n",
      "25152      0.0                 85.0                          3   \n",
      "25153  21941.0                 96.0                          0   \n",
      "25154      0.0                 77.0                          0   \n",
      "\n",
      "          Policy Type  Vehicle Class Total Claim Amount  \n",
      "0                 NaN            NaN                NaN  \n",
      "1                 NaN            NaN                NaN  \n",
      "2                 NaN            NaN                NaN  \n",
      "3                 NaN            NaN                NaN  \n",
      "4                 NaN            NaN                NaN  \n",
      "...               ...            ...                ...  \n",
      "25150   Personal Auto  Four-Door Car         198.234764  \n",
      "25151  Corporate Auto  Four-Door Car         379.200000  \n",
      "25152  Corporate Auto  Four-Door Car         790.784983  \n",
      "25153   Personal Auto  Four-Door Car         691.200000  \n",
      "25154  Corporate Auto   Two-Door Car         369.600000  \n",
      "\n",
      "[25155 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# -Combine- the data from the three dataframes into a single dataframe, named -\"customer_data\"-, \n",
    "#--using appropriate -merging-, -concatenating-, and -joining techniques-.\n",
    "\n",
    "# concatenating:\n",
    "file1 = pd.read_csv('file1.csv')\n",
    "file2_clean = pd.read_csv('file2_clean.csv')\n",
    "file3_clean = pd.read_csv('file3_clean.csv')\n",
    "\n",
    "df1 = pd.DataFrame(file1)\n",
    "df2 = pd.DataFrame(file2_clean)\n",
    "df3 = pd.DataFrame(file3_clean)\n",
    "\n",
    "customer_data = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "print(customer_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8867f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 1007\n",
      "Number of Columns: 17\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(file1)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\n",
    "num_rows = shape[0]\n",
    "num_columns = shape[1]\n",
    "\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39273a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 12074\n",
      "Number of Columns: 11\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(file2_clean)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\n",
    "num_rows = shape[0]\n",
    "num_columns = shape[1]\n",
    "\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4167fa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 12074\n",
      "Number of Columns: 11\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(file3_clean)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\n",
    "num_rows = shape[0]\n",
    "num_columns = shape[1]\n",
    "\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd0a9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concatenated DataFrame does not contain all rows and columns of the original DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# -Verify- that the -customer_data dataframe- contains -all the rows and columns- from the three original dataframes.\n",
    "\n",
    "# Verify that the shape matches the sum of shapes of original DataFrames\n",
    "original_shapes_sum = (df1.shape[0] + df2.shape[0] + df3.shape[0], df1.shape[1])\n",
    "if customer_data.shape == original_shapes_sum:\n",
    "    print(\"The concatenated DataFrame contains all rows and columns of the original DataFrames.\")\n",
    "else:\n",
    "    print(\"The concatenated DataFrame does not contain all rows and columns of the original DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd457378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Rows in DataFrame 1:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "Missing Rows in DataFrame 2:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "Missing Rows in DataFrame 3:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "customer_data = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "missing_rows_df1 = customer_data[~customer_data.isin(df1)].dropna()\n",
    "missing_rows_df2 = customer_data[~customer_data.isin(df2)].dropna()\n",
    "missing_rows_df3 = customer_data[~customer_data.isin(df3)].dropna()\n",
    "\n",
    "print(\"Missing Rows in DataFrame 1:\")\n",
    "print(missing_rows_df1)\n",
    "\n",
    "print(\"Missing Rows in DataFrame 2:\")\n",
    "print(missing_rows_df2)\n",
    "\n",
    "print(\"Missing Rows in DataFrame 3:\")\n",
    "print(missing_rows_df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3caa30a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Columns in DataFrame 1:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "Missing Columns in DataFrame 2:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "Missing Columns in DataFrame 3:\n",
      "Empty DataFrame\n",
      "Columns: [CONTROLN, STATE, GENDER, HV1, IC1, IC4, HVP1, IC5, POBC1, POBC2, IC2, IC3, AVGGIFT, TCODE, DOB, DOMAIN, TARGET_D, Customer, ST, Education, Customer Lifetime Value, Income, Monthly Premium Auto, Number of Open Complaints, Policy Type, Vehicle Class, Total Claim Amount]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "customer_data = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "missing_columns_df1 = customer_data[~customer_data.isin(df1)].dropna()\n",
    "missing_columns_df2 = customer_data[~customer_data.isin(df2)].dropna()\n",
    "missing_columns_df3 = customer_data[~customer_data.isin(df3)].dropna()\n",
    "\n",
    "print(\"Missing Columns in DataFrame 1:\")\n",
    "print(missing_columns_df1)\n",
    "\n",
    "print(\"Missing Columns in DataFrame 2:\")\n",
    "print(missing_columns_df2)\n",
    "\n",
    "print(\"Missing Columns in DataFrame 3:\")\n",
    "print(missing_columns_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dba3dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Columns in DataFrame 1:\n",
      "Index([], dtype='object')\n",
      "Duplicate Columns in DataFrame 2:\n",
      "Index([], dtype='object')\n",
      "Duplicate Columns in DataFrame 3:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def find_duplicate_columns(df):\n",
    "    duplicates = df.columns[df.columns.duplicated()]\n",
    "    return duplicates\n",
    "\n",
    "duplicates_df1 = find_duplicate_columns(df1)\n",
    "duplicates_df2 = find_duplicate_columns(df2)\n",
    "duplicates_df3 = find_duplicate_columns(df3)\n",
    "\n",
    "print(\"Duplicate Columns in DataFrame 1:\")\n",
    "print(duplicates_df1)\n",
    "\n",
    "print(\"Duplicate Columns in DataFrame 2:\")\n",
    "print(duplicates_df2)\n",
    "\n",
    "print(\"Duplicate Columns in DataFrame 3:\")\n",
    "print(duplicates_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b85c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are not identical in all DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# Check column names in the original DataFrames\n",
    "columns_df1 = set(df1.columns)\n",
    "columns_df2 = set(df2.columns)\n",
    "columns_df3 = set(df3.columns)\n",
    "\n",
    "# Check if column names are identical or in the desired order\n",
    "if columns_df1 == columns_df2 == columns_df3:\n",
    "    print(\"Column names are identical in all DataFrames.\")\n",
    "else:\n",
    "    print(\"Column names are not identical in all DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae00cb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows is different in the DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in the original DataFrames\n",
    "num_rows_df1 = df1.shape[0]\n",
    "num_rows_df2 = df2.shape[0]\n",
    "num_rows_df3 = df3.shape[0]\n",
    "\n",
    "# Check if the number of rows is the same in all DataFrames\n",
    "if num_rows_df1 == num_rows_df2 == num_rows_df3:\n",
    "    print(\"Number of rows is the same in all DataFrames.\")\n",
    "else:\n",
    "    print(\"Number of rows is different in the DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "390f77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types are not identical in all DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# Check data types in the original DataFrames\n",
    "dtypes_df1 = df1.dtypes\n",
    "dtypes_df2 = df2.dtypes\n",
    "dtypes_df3 = df3.dtypes\n",
    "\n",
    "# Check if data types are identical or compatible in all DataFrames\n",
    "if dtypes_df1.equals(dtypes_df2) and dtypes_df1.equals(dtypes_df3):\n",
    "    print(\"Data types are identical in all DataFrames.\")\n",
    "else:\n",
    "    print(\"Data types are not identical in all DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {},
   "source": [
    "## Alternative - Bonus\n",
    "\n",
    "If in the previous lab you created your cleaning and formatting function, or if you want to do it now, instead of using the two clean files provided above, you can use your function to clean and format the data in these two raw files, and work with your clean files instead:\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Observation: \n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {},
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {},
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains information such as\n",
    "#--demographics, policy details, vehicle information, and the customer's response to the last marketing campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d7b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal is to explore and analyze this data by performing: \n",
    "    # data cleaning,\n",
    "    # formatting, \n",
    "    # and structuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {},
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You work at the marketing department and you want to know which -sales channel- brought the -most sales- \n",
    "#--in terms of -total revenue-. \n",
    "# Using -pivot-, create a -summary table- showing the -total revenue- for each sales channel\n",
    "#--(branch, call center, web, and mail). \n",
    "    # -Round- the total revenue to 2 decimal points. \n",
    "    # -Analyze- the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4a45c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'marketing_customer_analysis_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Using -pivot-, create a -summary table- showing the -total revenue- for each sales channel\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#--(branch, call center, web, and mail). \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(marketing_customer_analysis_clean)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Use pivot to create a summary table\u001b[39;00m\n\u001b[1;32m      6\u001b[0m summary_table \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpivot(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'marketing_customer_analysis_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Using -pivot-, create a -summary table- showing the -total revenue- for each sales channel\n",
    "#--(branch, call center, web, and mail). \n",
    "df = pd.DataFrame(marketing_customer_analysis_clean)\n",
    "\n",
    "# Use pivot to create a summary table\n",
    "summary_table = df.pivot(index='Category', columns=None, values='Value', aggfunc='sum')\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "529db4fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'marketing_customer_analysis_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -Round- the total revenue to 2 decimal points. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(marketing_customer_analysis_clean)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Round all numeric columns to 2 decimal places\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_rounded \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'marketing_customer_analysis_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# -Round- the total revenue to 2 decimal points. \n",
    "df = pd.DataFrame(marketing_customer_analysis_clean)\n",
    "\n",
    "# Round all numeric columns to 2 decimal places\n",
    "df_rounded = df.round(2)\n",
    "\n",
    "# Display the rounded DataFrame\n",
    "print(df_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdba668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Analyze- the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {},
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a -pivot table- that shows the -average customer lifetime value- per -gender- and -education level-.\n",
    "# -Analyze- the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cca29f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'marketing_customer_analysis_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a -pivot table- that shows the -average customer lifetime value- per -gender- and -education level-.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(marketing_customer_analysis_clean)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Add a column for customer count (you can use your own data)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_lifetime_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'marketing_customer_analysis_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a -pivot table- that shows the -average customer lifetime value- per -gender- and -education level-.\n",
    "df = pd.DataFrame(marketing_customer_analysis_clean)\n",
    "\n",
    "# Add a column for customer count (you can use your own data)\n",
    "df['customer_lifetime_value'] = 1\n",
    "\n",
    "# Create a pivot table to calculate the average customer count per Gender and Education\n",
    "pivot_table = pd.pivot_table(df, values='customer_lifetime_value', index='gender', columns='education', aggfunc='mean')\n",
    "\n",
    "# Display the pivot table\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Analyze- the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {},
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
